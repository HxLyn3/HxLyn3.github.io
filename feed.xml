<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://hxlyn3.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://hxlyn3.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-02-17T02:56:38+00:00</updated><id>https://hxlyn3.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">ICLR 2025 | Any-step Dynamics Model for Policy Optimization</title><link href="https://hxlyn3.github.io/blog/2025/admpo/" rel="alternate" type="text/html" title="ICLR 2025 | Any-step Dynamics Model for Policy Optimization"/><published>2025-02-16T22:33:00+00:00</published><updated>2025-02-16T22:33:00+00:00</updated><id>https://hxlyn3.github.io/blog/2025/admpo</id><content type="html" xml:base="https://hxlyn3.github.io/blog/2025/admpo/"><![CDATA[<p><a href="https://zhuanlan.zhihu.com/p/23899000670">ICLR 2025 | ADMPO：跨任意步预测的动力学模型能够有效提升有模型强化学习</a> <a href="https://zhuanlan.zhihu.com/p/23899000670">24年在 @俞扬 老师的指导下完成了一个关于model-based reinforcement learning (MBRL)的工作，方法简单有效，已被ICLR’2025接收。这也是我个人博士阶段的第一篇一作文章，在这里分享下文章的主要内容。</a></p>]]></content><author><name></name></author><category term="paper-sharing"/><category term="RL"/><summary type="html"><![CDATA[ICLR 2025 | ADMPO：跨任意步预测的动力学模型能够有效提升有模型强化学习 24年在 @俞扬 老师的指导下完成了一个关于model-based reinforcement learning (MBRL)的工作，方法简单有效，已被ICLR’2025接收。这也是我个人博士阶段的第一篇一作文章，在这里分享下文章的主要内容。]]></summary></entry></feed>
<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://hxlyn3.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://hxlyn3.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-02-17T07:49:36+00:00</updated><id>https://hxlyn3.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">ICLR 2025 | Any-step Dynamics Model for Policy Optimization</title><link href="https://hxlyn3.github.io/blog/2025/admpo/" rel="alternate" type="text/html" title="ICLR 2025 | Any-step Dynamics Model for Policy Optimization"/><published>2025-02-16T22:33:00+00:00</published><updated>2025-02-16T22:33:00+00:00</updated><id>https://hxlyn3.github.io/blog/2025/admpo</id><content type="html" xml:base="https://hxlyn3.github.io/blog/2025/admpo/"><![CDATA[<p>24年在 @俞扬 老师的指导下完成了一个关于model-based reinforcement learning (MBRL)的工作，方法简单有效，已被ICLR’2025接收。这也是我个人博士阶段的第一篇一作文章，在这里分享下文章的主要内容…</p> <p><a href="https://zhuanlan.zhihu.com/p/23899000670">main text</a></p>]]></content><author><name></name></author><category term="paper-sharing"/><category term="RL"/><summary type="html"><![CDATA[24年在 @俞扬 老师的指导下完成了一个关于model-based reinforcement learning (MBRL)的工作，方法简单有效，已被ICLR’2025接收。这也是我个人博士阶段的第一篇一作文章，在这里分享下文章的主要内容…]]></summary></entry></feed>